{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80f8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e95f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 113.9959\n",
      "Epoch 100, Loss: 28.0720\n",
      "Epoch 200, Loss: 0.0049\n",
      "Epoch 300, Loss: 0.0049\n",
      "Epoch 400, Loss: 0.0049\n",
      "Epoch 500, Loss: 0.0049\n",
      "Epoch 600, Loss: 0.0049\n",
      "Epoch 700, Loss: 0.0049\n",
      "Epoch 800, Loss: 0.0049\n",
      "Epoch 900, Loss: 0.0049\n",
      "\n",
      "Final Weights:\n",
      "W1: [[1.41883523]]\n",
      "W2: [[1.41886676]]\n",
      "\n",
      "Prediction:\n",
      " [[ 0.        ]\n",
      " [ 2.01313815]\n",
      " [ 4.02627629]\n",
      " [ 6.03941444]\n",
      " [ 8.05255258]\n",
      " [10.06569073]\n",
      " [12.07882888]\n",
      " [14.09196702]\n",
      " [16.10510517]\n",
      " [18.11824332]]\n",
      "\n",
      "y True:\n",
      " [[ 0]\n",
      " [ 2]\n",
      " [ 4]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [10]\n",
      " [12]\n",
      " [14]\n",
      " [16]\n",
      " [18]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Goal y = 2x\n",
    "x = np.array([np.arange(0, 10)]).T\n",
    "y = 2 * x\n",
    "\n",
    "# Initialize params, has 1 hidden layers with 1 neurons, no bias\n",
    "def init_params(input_shape, output_shape):\n",
    "  W1 = np.random.rand(input_shape, input_shape) * 0.01\n",
    "  W2 = np.random.rand(input_shape, output_shape) * 0.01\n",
    "  return W1, W2\n",
    "\n",
    "# Forward propagation\n",
    "def forward(x, W1, W2):\n",
    "  hidden =  x @ W1\n",
    "  output = hidden @ W2\n",
    "  return hidden, output\n",
    "\n",
    "# MSE loss\n",
    "def MSE(y_true, y_pred):\n",
    "  return np.mean(np.square(y_true-y_pred))\n",
    "\n",
    "# Backward propagation\n",
    "def backward(x, y, W1, W2, H, O, lr=0.01):\n",
    "  dL_dO = 2 * (O - y) / O.shape[0]\n",
    "  \n",
    "  dO_dW2 = H\n",
    "  dL_dW2 = dO_dW2.T @ dL_dO\n",
    "  \n",
    "  dO_dH = W2\n",
    "  dH_dW1 = x\n",
    "  dL_dW1 = dH_dW1.T @ (dL_dO @ dO_dH.T)\n",
    "\n",
    "  # Clip weight to handle overflow\n",
    "  # Because we don't use activation function here\n",
    "  np.clip(dL_dW1, -1, 1, out=dL_dW1)\n",
    "  np.clip(dL_dW2, -1, 1, out=dL_dW2)\n",
    "\n",
    "  W2 -= lr * dL_dW2\n",
    "  W1 -= lr * dL_dW1\n",
    "\n",
    "  return W1, W2\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "W1, W2 = init_params(1, 1)\n",
    "for epoch in range(epochs):\n",
    "  H, O = forward(x, W1, W2)\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    loss = MSE(y, O)\n",
    "    print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "  W1, W2 = backward(x, y, W1, W2, H, O)\n",
    "\n",
    "print(\"\\nFinal Weights:\")\n",
    "print(\"W1:\", W1)\n",
    "print(\"W2:\", W2)\n",
    "print(\"\\nPrediction:\\n\", forward(x, W1, W2)[1])\n",
    "print(\"\\ny True:\\n\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScienceClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
